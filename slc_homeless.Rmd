---
title: 'STAT 651: Project'
author: "Skyler Gray"
date: "November 9, 2021"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(ggmap)
library(tidyverse)
library(lubridate)
library(flextable)
library(kableExtra)
library(cowplot)
library(rstan)

# Set random seed
set.seed(1122)

## Settings for Stan
nCores <- parallel::detectCores() - 1
options(mc.cores = nCores)          # Use all available cores.
rstan_options(auto_write = TRUE)    # Cache compiled code.
rstan_options(javascript = FALSE)     # FIXME: Effort to reduce RStudio Stan probs. May be helping.

# Set ggplot theme
mytheme <- theme_bw()
theme_set(mytheme)

# Picture saving settings
pic_width <- 7
pic_height <- 4
pic_unit <- 'in'
```

```{r read-data}
covid <- read_csv('data/covid19_cases_saltlakecounty.csv')
homeless_init <- read_csv('data/slc_homeless_only_locations.csv') %>%
  mutate(district = as.character(district))
homeless <- read_csv('data/homeless_requests.csv',
                     col_types = cols(district = col_character())) %>%
  select(-date_closed) %>%
  rename(date = date_created)
pop_2019 <- read_csv('data/slc_population_2019_est_tracts.csv') %>%
  select(-map_code)
inc_2019 <- read_csv('data/slc_income_2019_est_tracts.csv') %>%
  select(-map_code)
# pop <- read_csv('data/slc_population_2019_est.csv',
#                 col_types = cols(district = col_character()))

combined <- homeless %>%
  left_join(pop_2019, by = 'tract') %>%
  left_join(inc_2019, by = 'tract') %>%
  left_join(covid, by = 'date') %>%
  # mutate(has_income = ifelse(income <= 0, 0, 1),
  #        logincome = ifelse(income <= 0, 0, log(income))) %>%
  # Filter out the 8 observations in the airport tract; no income there
  filter(tract != 980000) %>%
  mutate(logincome = log(income)) %>%
  select(id, date, long, lat, cases_avg7, district, 
         tract, density, logincome, days_open)
  

# rm(covid, homeless, inc_2019, pop_2019)
```


# Introduction

```{r request-map}
# Add request locations on SLC map
bb <- make_bbox(lon = long, lat = lat, data = homeless)
mymap <- get_map(location = bb, zoom = 11,
                 maptype = "hybrid", source = "google",
                 color = 'bw')

# Unfiltered homelessness report map
p <- ggmap(mymap) + 
  geom_point(data = homeless_init, 
             aes(x = long, y = lat, col = district),
             alpha = 0.6,
             size = 2) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  scale_color_brewer(type = 'qual', palette = 2) +
  scale_x_continuous(limits = c(min(homeless_init$long)-0.001,
                                max(homeless_init$long)+0.001)) +
  scale_y_continuous(limits = c(min(homeless_init$lat)-0.001,
                                max(homeless_init$lat)+0.001)) +
  labs(col = 'District',
       title = paste0( 'Reports of homelessness concern since ',
                       date(min(covid$date)) ))

ggsave('plots/reports_map.png',
       plot = p,
       device = 'png',
       dpi = 300,
       width = pic_width, 
       height = pic_height,
       units = pic_unit)

# Filtered (data used for the analysis) homelessness report map
p <- ggmap(mymap) + 
  geom_point(data = homeless, 
             aes(x = long, y = lat, col = district),
             alpha = 0.6,
             size = 2) +
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        axis.title = element_blank()) +
  scale_color_brewer(type = 'qual', palette = 2) +
  scale_x_continuous(limits = c(min(homeless$long)-0.001,
                                max(homeless$long)+0.001)) +
  scale_y_continuous(limits = c(min(homeless$lat)-0.001,
                                max(homeless$lat)+0.001)) +
  labs(col = 'District',
       title = paste0( 'Reports of homelessness concern since ',
                       date(min(covid$date)) ))

ggsave('plots/reports_map_filtered.png',
       plot = p,
       device = 'png',
       dpi = 300,
       width = pic_width, 
       height = pic_height,
       units = pic_unit)

```


# The Data

```{r}
combined %>%
  select(district, cases_avg7, density, logincome, days_open) %>%
  mutate(across(cases_avg7:logincome, function(x) round(x, 1))) %>%
  flextable() %>%
  set_header_labels(district = 'District',
                    cases_avg7 = 'Average New COVID Cases',
                    density = 'Population Density',
                    logincome = 'Log(Median Household Income)',
                    days_open = 'Days Open') %>%
  autofit() %>%
  theme_zebra()
```


# Exploratory Data Analysis

```{r inside-analysis, eval=FALSE}
# Sample size is not large enough to predict differences in neighborhoods
homeless %>%
  group_by(district, neighborhood) %>%
  summarize(n = n(),
            avg_date = mean(date),
            min_date = min(date)) %>%
  arrange(neighborhood) %>%
  View()
```

```{r sample-size-mean-days}
combined %>%
  group_by(district) %>%
  summarize(n = n(),
            days_open = mean(days_open) %>%
              round(2)) %>%
  flextable() %>%
  set_header_labels(district = 'District',
                    days_open = 'Days Open') %>%
  autofit() %>%
  theme_zebra()
```

```{r eda-plots}
p <- combined %>%
  ggplot(aes(days_open)) +
  geom_density() +
  labs(x = 'Days Open', y = 'Density')

p1 <- combined %>%
  ggplot(aes(date, log(days_open))) +
  geom_jitter(alpha = 0.5) +
  labs(x = 'Date', y = 'log(Days Open)')

p2 <- combined %>%
  ggplot(aes(district, log(days_open))) +
  geom_boxplot() +
  labs(x = 'District', y = 'log(Days Open)')

p3 <- combined %>%
  ggplot(aes(cases_avg7, log(days_open))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = 'lm',
              se = FALSE) +
  labs(x = 'New COVID Cases (Rolling 7-Day Avg)',
       y = 'log(Days Open)')

p4 <- combined %>%
  ggplot(aes(logincome, log(days_open))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = 'lm',
              se = FALSE) +
  labs(x = 'log(Income)', y = 'log(Days Open)')

p5 <- combined %>%
  ggplot(aes(density, log(days_open))) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = 'lm',
              se = FALSE) +
  labs(x = 'Population Density (Pop per Sq. Mile)',
       y = 'log(Days Open)')

# Save plots
plot_grid(p1, p3, p4, p5, 
          nrow = 2, byrow = TRUE) %>%
  ggsave(filename = 'plots/eda_cont_predictors.png',
         plot = .,
         device = 'png',
         dpi = 300,
         width = pic_width, 
         height = pic_height,
         units = pic_unit)

ggsave('plots/eda_days_density.png',
       plot = p,
       device = 'png',
       dpi = 300,
       width = pic_width, 
       height = pic_height,
       units = pic_unit)

ggsave('plots/eda_days_districts.png',
       plot = p2,
       device = 'png',
       dpi = 300,
       width = pic_width, 
       height = pic_height,
       units = pic_unit)
```



# Fit Model: GLM

```{r scale-data}
X <- model.matrix(~ district + density + logincome + cases_avg7,
                  data = combined)
contvars_idx <- 8:10
vars_scaled <- scale(X[,contvars_idx])
X[,contvars_idx] <- vars_scaled
y <- combined$days_open
```

```{r trad-glm-fit}
fit <- glm(days_open ~ X - 1,
           data = combined,
           family = poisson)
summary(fit)
confint(fit) %>%
  round(3)
```




# Fit Model: MCMC Metropolis Hastings

```{r}
loglike <- function(beta) {
  sum( dpois(y, exp(X%*%beta), log = TRUE) )
}
logprior <- function(beta) {
  mu_0 <- 0
  tau2_0 <- 1/100
  
  sum( dnorm(beta, mu_0, sqrt(1/tau2_0), log = TRUE) )
}
logpost <- function(beta) {
  loglike(beta) + logprior(beta)
}

# Stabilize computations of log(posterior) because even the max val is super small
betahat <- optim(coef(fit), function(beta) -logpost(beta))
logpost_max <- -betahat$value

logpost_adj <- function(beta) {
  # subtract maximum logpost value to stabilize computations
  loglike(beta) + logprior(beta) - logpost_max
}
```

```{r sample-slice}
doit <- function(ndraws = 10000, width = rep(1, 10), warmup = 1000) {
  n_evals <- 0
  f <- function(pars) {
    n_evals <<- n_evals + 1
    logpost_adj(pars)
  }
  draws <- matrix(0, nrow = ndraws, ncol = 10)
  current <- rnorm(10, 0, 1)
  current <- coef(fit) # Start with GLM fit
  f_current <- f(current)
  
  for (i in 1:ndraws) {
    for (j in 1:ncol(draws)) {
      # Slice sample beta1
      y_slice <- log(runif(1, 0, exp(f_current)))
      l <- current[j] - runif(1)*width[j]
      l_prop <- current
      l_prop[j] <- l
      u <- l + width[j]
      u_prop <- current
      u_prop[j] <- u
      
      while (y_slice < f(l_prop)) {
        l <- l - width[j]
        l_prop[j] <- l
      } 
      while (y_slice < f(u_prop)) {
        u <- u + width[j]
        u_prop[j] <- u
      }
      while (TRUE) {
        candidate <- runif(1, l, u)
        cand_prop <- current; cand_prop[j] <- candidate
        f_candidate <- f(cand_prop)
        if (y_slice > f_candidate ) {
          if ( candidate < current[j] ) l <- candidate
          else u <- candidate
        } else break
      }
      current[j] <- candidate
      f_current <- f_candidate
    }
    draws[i,] <- current
  }
  
  return(list(draws = draws[-c(1:warmup),],
              evals_per_draw = n_evals/ndraws))
}

ndraws <- 5e4
warmup <- 1000
width <- rep(0.08, 10)
test <- doit(ndraws = ndraws, width = width, warmup = warmup)
test$evals_per_draw
ess <- floor( coda::effectiveSize(test$draws) )

cat('Effective Sample Sizes:\n')
ess

```

```{r}
cbind(colMeans(test$draws),
      apply(test$draws, 2, 
            function(x) quantile(x, c(0.025, 0.975))) %>%
        t())
```


```{r metropolis, eval=FALSE}
# Rookie implementation of Metropolis algorithm
#  NOT efficient; slice sampler works much better

ndraws <- 10000
nbetas <- 10
accept <- 0
draws <- matrix(0, nrow = ndraws, ncol = nbetas)
state <- rep(0.5, nbetas)
for (i in 1:ndraws) {
  proposal <- state + rnorm(nbetas, 0, 0.1)
  metropolis <- logpost(proposal) - logpost(state)
  if (log(runif(1)) < metropolis) {
    draws[i,] <- proposal
    state <- proposal
    accept <- accept + 1
  } else draws[i,] <- state
}
plot(draws[,4], type = 'l')
accept
coda::effectiveSize(draws)
```


# Fit Model: Stan

```{r stan-model}
N <- nrow(combined)

# Prior values
mu_0 <- 0
tau2_0 <- 1/100

# Fit Stan model
m <- stan_model(model_code = readLines("model.stan"))
data <- list(N = N,
             y = y, 
             X = X,
             mu_0 = mu_0,
             tau2_0 = tau2_0)
fit_stan <- sampling(m, data = data,
                     iter = 5000, warmup = 1000,
                     chains = 1)
                     # iter = 10000, warmup = 1000, # MUST HAVE WARMUP > 9(?)
                     # chains = nCores)
```


```{r stan-model-diagnostics}
fit_extr <- extract(fit_stan)

print(fit_stan, probs = c(0.05, 0.95))

plot(fit_extr$beta[,1], type = 'l')
coda::effectiveSize(fit_extr$beta)
```

```{r}
beta <- fit_extr$beta

# Pairwise comparisons
significant <- matrix(0, nrow = 7, ncol = 7)
ci <- apply(beta[,c(2:7)], 2, function(x) quantile(x, c(0.025, 0.975)))
significant[1, c(2:7)] <- ifelse(ci[1,] * ci[2,] > 0, 1, 0)
significant[c(2:7), 1] <- ifelse(ci[1,] * ci[2,] > 0, 1, 0)
for (i in 2:6) {
  for (j in (i+1):7) {
    ci <- quantile(beta[,i] - beta[,j], c(0.025, 0.975))
    sig <- ifelse(ci[1] * ci[2] > 0, 1, 0)
    significant[i, j] <- sig
    significant[j, i] <- sig
  }
}
significant

# Plot district effects
beta_districts <- beta[,1:7]
for (j in 2:7) {
  beta_districts[,j] <- beta_districts[,1] + beta_districts[,j]
}
est <- colMeans(beta_districts)
ci <- apply(beta_districts, 2, function(x) quantile(x, c(0.025, 0.975)))
lwr <- ci[1,]
upr <- ci[2,]

beta_districts <- data.frame(district = as.character(1:7),
                             est = exp(est),
                             lwr = exp(lwr),
                             upr = exp(upr))
p <- beta_districts %>%
  ggplot(aes(district, est, ymin = lwr, ymax = upr)) +
  geom_point() +
  geom_errorbar() +
  labs(x = 'District',
       y = 'Mean Days Request is Open',
       title = 'Posterior mean and credible interval estimates')

ggsave('plots/post_district_ci.png',
       plot = p,
       device = 'png',
       dpi = 300,
       width = pic_width, 
       height = pic_height,
       units = pic_unit)
```




```{r shapefile, eval=FALSE}
library(rgdal)
library(rgeos) # For tidy() function
library(broom) #contains tidy() function which converts polygons to data.frame

path <- 'data/SLC_Census_Tracts_2010'
myShp <- readOGR(dsn = path, layer = 'CensusTracts2010')

myShp@data$id <- rownames(myShp@data) #Assign ID to each polygon
myShp.df <- tidy(myShp, region = "id") #Convert polygon info to data.frame()
myShp.df <- merge(myShp.df, myShp@data, by = "id") #Merge data w/polygon data.frame

myShp.df %>%
  ggplot(aes(x=long, y=lat, group = group)) + 
  geom_polygon(color="black", fill='gray')
```
